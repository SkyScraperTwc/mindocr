system:
  mode: 1 # 0 for graph mode, 1 for pynative mode in MindSpore
  distribute: False
  amp_level: 'O0'
  seed: 2022
  # log_interval: 10
  val_while_train: True
  drop_overflow_update: False

model:
  type: kie
  transform: null
  backbone:
    name: layoutxlm_for_re
    pretrained: True
    checkpoints:

postprocess:
  name: VQAReTokenLayoutLMPostProcess
  class_path: &class_path train_data/xfund/class_list_xfun.txt

metric:
  name: VQAReTokenMetric
  main_indicator: hmean

loss:
  name: LossFromOutput
  key: "backbone_out"

scheduler:
  scheduler: polynomial_decay
  lr: 0.00005
  min_lr: 0.0000002
  num_epochs: 200
  warmup_epochs: 10

optimizer:
  opt: adam
  beta1: 0.9
  beta2: 0.999
  clip_norm: 10
  filter_bias_and_bn: False
  weight_decay: 0.0005

train:
  ckpt_save_dir: './tmp_kie_re'
  dataset_sink_mode: False
  dataset:
    type: KieDataset
    dataset_root: train_data
    data_dir: xfund/zh_train/image
    label_file: xfund/zh_train/train.json
    sample_ratio: 1.0
    transform_pipeline:
      - DecodeImage:
          img_mode: RGB
          to_float32: False
      - VQATokenLabelEncode:
          contains_re: True
          algorithm: &algorithm LayoutXLM
          class_path: *class_path
      - VQATokenPad:
          max_seq_len: &max_seq_len 512
          return_attention_mask: True
      - VQAReTokenRelation:
      - VQAReTokenChunk:
          max_seq_len: *max_seq_len
      - TensorizeEntitiesRelations:
      - LayoutResize:
          size: [ 224, 224 ]
      - NormalizeImage:
          bgr_to_rgb: False
          is_hwc: True
          mean: imagenet
          std: imagenet
      - ToCHWImage:
      #  the order of the dataloader list, matching the network input and the input labels for the loss function, and optional data for debug/visualize
    output_columns: [ 'input_ids', 'bbox','attention_mask', 'token_type_ids', 'image', 'entities', 'relations' ]
    net_input_column_index: [ 0, 1, 2, 3, 4, 5, 6 ] # input indices for network forward func in output_columns
    label_column_index: [ 5, 6 ] # input indices marked as label

  loader:
    shuffle: True
    batch_size: 4
    drop_remainder: True
    num_workers: 8

eval:
  ckpt_load_path: './tmp_kie_re/best.ckpt'
  dataset_sink_mode: False
  dataset:
    type: KieDataset
    dataset_root: train_data
    data_dir: xfund/zh_val/image
    label_file: xfund/zh_val/val.json
    sample_ratio: 1.0
    shuffle: False
    transform_pipeline:
      - DecodeImage:
          img_mode: RGB
          to_float32: False
      - VQATokenLabelEncode:
          contains_re: True
          algorithm: *algorithm
          class_path: *class_path
      - VQATokenPad:
          max_seq_len: *max_seq_len
          return_attention_mask: True
      - VQAReTokenRelation:
      - VQAReTokenChunk:
          max_seq_len: *max_seq_len
      - TensorizeEntitiesRelations:
      - LayoutResize:
          size: [ 224, 224 ]
      - NormalizeImage:
          bgr_to_rgb: False
          is_hwc: True
          mean: imagenet
          std: imagenet
      - ToCHWImage:
      #  the order of the dataloader list, matching the network input and the labels for evaluation
    output_columns: [ 'input_ids', 'bbox','attention_mask', 'token_type_ids', 'image', 'entities', 'relations' ]
    net_input_column_index: [ 0, 1, 2, 3, 4, 5, 6 ] # input indices for network forward func in output_columns
    label_column_index: [ 5, 6 ] # input indices marked as label
  #    num_keys_of_labels: 2 # num labels

  loader:
    shuffle: False
    batch_size: 4
    drop_remainder: False
    num_workers: 1
